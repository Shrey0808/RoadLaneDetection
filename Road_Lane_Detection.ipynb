{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wW2b8Z0yo3b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3XIXE_hyo3g"
      },
      "outputs": [],
      "source": [
        "def RGB_color_selection(image):\n",
        "    #White color mask\n",
        "    lower_threshold = np.uint8([200, 200, 200])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    white_mask = cv2.inRange(image, lower_threshold, upper_threshold)\n",
        "\n",
        "    #Yellow color mask\n",
        "    lower_threshold = np.uint8([175, 175,   0])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    yellow_mask = cv2.inRange(image, lower_threshold, upper_threshold)\n",
        "\n",
        "    #Combine white and yellow masks\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
        "\n",
        "    return masked_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PyN3YZ2yo3h"
      },
      "outputs": [],
      "source": [
        "def convert_hsv(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ap56PjAyo3i"
      },
      "outputs": [],
      "source": [
        "def HSV_color_selection(image):\n",
        "    #Convert the input image to HSV\n",
        "    converted_image = convert_hsv(image)\n",
        "\n",
        "    #White color mask\n",
        "    lower_threshold = np.uint8([0, 0, 210])\n",
        "    upper_threshold = np.uint8([255, 30, 255])\n",
        "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "\n",
        "    #Yellow color mask\n",
        "    lower_threshold = np.uint8([18, 80, 80])\n",
        "    upper_threshold = np.uint8([30, 255, 255])\n",
        "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "\n",
        "    #Combine white and yellow masks\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
        "\n",
        "    return masked_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_KGC8lsyo3j"
      },
      "outputs": [],
      "source": [
        "def convert_hsl(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wH0roUd2yo3k"
      },
      "outputs": [],
      "source": [
        "def HSL_color_selection(image):\n",
        "    #Convert the input image to HSL\n",
        "    converted_image = convert_hsl(image)\n",
        "\n",
        "    #White color mask\n",
        "    lower_threshold = np.uint8([0, 200, 0])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "\n",
        "    #Yellow color mask\n",
        "    lower_threshold = np.uint8([10, 0, 100])\n",
        "    upper_threshold = np.uint8([40, 255, 255])\n",
        "    yellow_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "\n",
        "    #Combine white and yellow masks\n",
        "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
        "\n",
        "    return masked_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCNTySdvyo3m"
      },
      "outputs": [],
      "source": [
        "def gray_scale(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W07FGJAtyo3n"
      },
      "outputs": [],
      "source": [
        "def gaussian_smoothing(image, kernel_size = 13):\n",
        "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVERySj2yo3s"
      },
      "outputs": [],
      "source": [
        "def canny_detector(image, low_threshold = 50, high_threshold = 150):\n",
        "    return cv2.Canny(image, low_threshold, high_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaZS6vZhyo3t"
      },
      "outputs": [],
      "source": [
        "def region_selection(image):\n",
        "    mask = np.zeros_like(image)\n",
        "    if len(image.shape) > 2:\n",
        "        channel_count = image.shape[2]\n",
        "        ignore_mask_color = (255,) * channel_count\n",
        "    else:\n",
        "        ignore_mask_color = 255\n",
        "\n",
        "    rows, cols = image.shape[:2]\n",
        "    bottom_left  = [cols * 0.1, rows * 0.95]\n",
        "    top_left     = [cols * 0.4, rows * 0.6]\n",
        "    bottom_right = [cols * 0.9, rows * 0.95]\n",
        "    top_right    = [cols * 0.6, rows * 0.6]\n",
        "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
        "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
        "    masked_image = cv2.bitwise_and(image, mask)\n",
        "    return masked_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLQAINRgyo3u"
      },
      "outputs": [],
      "source": [
        "def hough_transform(image):\n",
        "    rho = 1\n",
        "    theta = np.pi/180\n",
        "    threshold = 20\n",
        "    minLineLength = 20\n",
        "    maxLineGap = 300\n",
        "    return cv2.HoughLinesP(image, rho = rho, theta = theta, threshold = threshold,\n",
        "                           minLineLength = minLineLength, maxLineGap = maxLineGap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXbAZWCZyo3v"
      },
      "outputs": [],
      "source": [
        "def draw_lines(image, lines, color = [0, 0, 255], thickness = 1):\n",
        "    image = np.copy(image)\n",
        "    for line in lines:\n",
        "        for x1,y1,x2,y2 in line:\n",
        "            cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVQzpgTryo3w"
      },
      "outputs": [],
      "source": [
        "def average_slope_intercept(lines):\n",
        "    left_lines    = [] #(slope, intercept)\n",
        "    left_weights  = [] #(length,)\n",
        "    right_lines   = [] #(slope, intercept)\n",
        "    right_weights = [] #(length,)\n",
        "\n",
        "    for line in lines:\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            if x1 == x2:\n",
        "                continue\n",
        "            slope = (y2 - y1) / (x2 - x1)\n",
        "            intercept = y1 - (slope * x1)\n",
        "            length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2))\n",
        "            if slope < 0:\n",
        "                left_lines.append((slope, intercept))\n",
        "                left_weights.append((length))\n",
        "            else:\n",
        "                right_lines.append((slope, intercept))\n",
        "                right_weights.append((length))\n",
        "    left_lane  = np.dot(left_weights,  left_lines) / np.sum(left_weights)  if len(left_weights) > 0 else None\n",
        "    right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if len(right_weights) > 0 else None\n",
        "    return left_lane, right_lane"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_joIEcyyo3x"
      },
      "outputs": [],
      "source": [
        "def pixel_points(y1, y2, line):\n",
        "    if line is None:\n",
        "        return None\n",
        "    slope, intercept = line\n",
        "    x1 = int((y1 - intercept)/slope)\n",
        "    x2 = int((y2 - intercept)/slope)\n",
        "    y1 = int(y1)\n",
        "    y2 = int(y2)\n",
        "    return ((x1, y1), (x2, y2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoPOl8atyo3x"
      },
      "outputs": [],
      "source": [
        "def lane_lines(image, lines):\n",
        "    left_lane, right_lane = average_slope_intercept(lines)\n",
        "    y1 = image.shape[0]\n",
        "    y2 = y1 * 0.6\n",
        "    left_line  = pixel_points(y1, y2, left_lane)\n",
        "    right_line = pixel_points(y1, y2, right_lane)\n",
        "    return left_line, right_line\n",
        "\n",
        "\n",
        "def draw_lane_lines(image, lines, color=[0, 0, 255], thickness=8):\n",
        "\n",
        "    line_image = np.zeros_like(image)\n",
        "    for line in lines:\n",
        "        if line is not None:\n",
        "            cv2.line(line_image, *line,  color, thickness)\n",
        "    return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip test_videos.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U4twqiT9WIx",
        "outputId": "ee833849-8db7-4285-f731-edaf5fb8c917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  test_videos.zip\n",
            "  inflating: test_videos/test1.mp4   \n",
            "  inflating: test_videos/test2.mp4   \n",
            "  inflating: test_videos/test3.mp4   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2WrJ7i3yo3y"
      },
      "outputs": [],
      "source": [
        "from moviepy import *\n",
        "from IPython.display import HTML\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiCbUnnlyo3y"
      },
      "outputs": [],
      "source": [
        "def frame_processor(image):\n",
        "    color_select = HSL_color_selection(image)\n",
        "    gray         = gray_scale(color_select)\n",
        "    smooth       = gaussian_smoothing(gray)\n",
        "    edges        = canny_detector(smooth)\n",
        "    region       = region_selection(edges)\n",
        "    hough        = hough_transform(region)\n",
        "    result       = draw_lane_lines(image, lane_lines(image, hough))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhNLDsydyo3z"
      },
      "outputs": [],
      "source": [
        "def process_video(test_video, output_video):\n",
        "    input_video = VideoFileClip(os.path.join('test_videos', test_video), audio=False)\n",
        "    processed = input_video.fl_image(frame_processor)\n",
        "    os.makedirs('output_videos', exist_ok=True)\n",
        "    processed.write_videofile(os.path.join('output_videos', output_video), audio=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_video_path = 'test3.mp4'\n",
        "output_video_path = 'test3_output.mp4'\n",
        "\n",
        "process_video(input_video_path, output_video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0VE8yq46ZNL",
        "outputId": "d177ad6f-6e09-404b-a88f-4ae3c8f72c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[A\n",
            "t:  35%|███▍      | 452/1297 [18:43<01:01, 13.67it/s, now=None]\u001b[A\n",
            "\u001b[A\n",
            "t:  35%|███▍      | 452/1297 [18:43<01:01, 13.67it/s, now=None]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video output_videos/test3_output.mp4.\n",
            "Moviepy - Writing video output_videos/test3_output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[A\n",
            "t:  35%|███▍      | 452/1297 [19:23<01:01, 13.67it/s, now=None]\u001b[A\n",
            "\u001b[A\n",
            "t:  35%|███▍      | 452/1297 [19:23<01:01, 13.67it/s, now=None]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output_videos/test3_output.mp4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}